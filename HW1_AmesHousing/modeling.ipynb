{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79505d3d",
   "metadata": {},
   "source": [
    "# Ames Housing Dataset Modeling\n",
    "\n",
    "This notebook contains model development for the Ames Housing dataset, including:\n",
    "- Missing value imputation\n",
    "- Data preprocessing\n",
    "- Train/test splitting\n",
    "- 10-fold cross validation with multiple models:\n",
    "  - Ridge Regression\n",
    "  - Lasso Regression\n",
    "  - Random Forest\n",
    "  - PyTorch Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c12b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a5871",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a3719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (adjust path as needed)\n",
    "try:\n",
    "    df = pd.read_csv('data/train.csv')\n",
    "except FileNotFoundError:\n",
    "    # Try alternative path\n",
    "    try:\n",
    "        df = pd.read_csv('train.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Please ensure the Ames Housing dataset (train.csv) is in the current directory or data/ folder\")\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb212a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0].sort_values(ascending=False)\n",
    "print(f\"Number of features with missing values: {len(missing_values)}\")\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1772dfc1",
   "metadata": {},
   "source": [
    "## 2. Missing Values Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target variable from features\n",
    "if 'SalePrice' in numeric_features:\n",
    "    numeric_features.remove('SalePrice')\n",
    "\n",
    "# Create imputers for numeric and categorical data\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Apply imputation\n",
    "df[numeric_features] = numeric_imputer.fit_transform(df[numeric_features])\n",
    "df[categorical_features] = categorical_imputer.fit_transform(df[categorical_features])\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"Missing values after imputation: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb07ba3",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32021d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target variable\n",
    "y = df['SalePrice']\n",
    "\n",
    "# Log transform the target variable (common for house prices)\n",
    "y = np.log1p(y)\n",
    "\n",
    "# Prepare the feature matrix\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "\n",
    "# Create a preprocessor for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2607970d",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1193a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b68029",
   "metadata": {},
   "source": [
    "## 5. Model Training with 10-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c890c281",
   "metadata": {},
   "source": [
    "### 5.1 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ridge Regression pipeline\n",
    "ridge_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "# Set up 10-fold cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "ridge_cv_scores = cross_val_score(ridge_pipeline, X_train, y_train, cv=kf, \n",
    "                                scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE to RMSE\n",
    "ridge_rmse_scores = np.sqrt(-ridge_cv_scores)\n",
    "\n",
    "print(\"Ridge Regression 10-fold CV Results:\")\n",
    "print(f\"Mean RMSE: {ridge_rmse_scores.mean():.4f}\")\n",
    "print(f\"Std RMSE: {ridge_rmse_scores.std():.4f}\")\n",
    "\n",
    "# Train on the full training set\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_ridge = ridge_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics on test set\n",
    "ridge_test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "ridge_test_r2 = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(f\"\\nTest RMSE: {ridge_test_rmse:.4f}\")\n",
    "print(f\"Test R²: {ridge_test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc108a4",
   "metadata": {},
   "source": [
    "### 5.2 Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lasso Regression pipeline\n",
    "lasso_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', Lasso(alpha=0.001))\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "lasso_cv_scores = cross_val_score(lasso_pipeline, X_train, y_train, cv=kf, \n",
    "                                 scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE to RMSE\n",
    "lasso_rmse_scores = np.sqrt(-lasso_cv_scores)\n",
    "\n",
    "print(\"Lasso Regression 10-fold CV Results:\")\n",
    "print(f\"Mean RMSE: {lasso_rmse_scores.mean():.4f}\")\n",
    "print(f\"Std RMSE: {lasso_rmse_scores.std():.4f}\")\n",
    "\n",
    "# Train on the full training set\n",
    "lasso_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lasso = lasso_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics on test set\n",
    "lasso_test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "lasso_test_r2 = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(f\"\\nTest RMSE: {lasso_test_rmse:.4f}\")\n",
    "print(f\"Test R²: {lasso_test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106585a7",
   "metadata": {},
   "source": [
    "### 5.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forest pipeline\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "rf_cv_scores = cross_val_score(rf_pipeline, X_train, y_train, cv=kf, \n",
    "                              scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE to RMSE\n",
    "rf_rmse_scores = np.sqrt(-rf_cv_scores)\n",
    "\n",
    "print(\"Random Forest 10-fold CV Results:\")\n",
    "print(f\"Mean RMSE: {rf_rmse_scores.mean():.4f}\")\n",
    "print(f\"Std RMSE: {rf_rmse_scores.std():.4f}\")\n",
    "\n",
    "# Train on the full training set\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics on test set\n",
    "rf_test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "rf_test_r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"\\nTest RMSE: {rf_test_rmse:.4f}\")\n",
    "print(f\"Test R²: {rf_test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31494a",
   "metadata": {},
   "source": [
    "### 5.4 PyTorch Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to preprocess the data for PyTorch\n",
    "# Apply preprocessing to the full dataset\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Define the Neural Network model\n",
    "class HousingNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HousingNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.layer4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the neural network\n",
    "def train_nn(X_train, y_train, input_dim, epochs=100, batch_size=32):\n",
    "    # Convert to PyTorch tensors\n",
    "    # Handle sparse matrix by converting to dense array first\n",
    "    from scipy import sparse\n",
    "    if sparse.issparse(X_train):\n",
    "        X_train_tensor = torch.FloatTensor(X_train.toarray())\n",
    "    else:\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        \n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = HousingNN(input_dim)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_nn(model, X_test, y_test):\n",
    "    # Handle sparse matrix\n",
    "    from scipy import sparse\n",
    "    if sparse.issparse(X_test):\n",
    "        X_test_tensor = torch.FloatTensor(X_test.toarray())\n",
    "    else:\n",
    "        X_test_tensor = torch.FloatTensor(X_test)\n",
    "        \n",
    "    y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_tensor)\n",
    "        mse = nn.MSELoss()(y_pred, y_test_tensor).item()\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Convert to numpy for R² calculation\n",
    "        y_pred_np = y_pred.numpy().flatten()\n",
    "        y_test_np = y_test.values\n",
    "        r2 = r2_score(y_test_np, y_pred_np)\n",
    "        \n",
    "    return rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 10-fold cross-validation with the Neural Network\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "nn_rmse_scores = []\n",
    "\n",
    "input_dim = X_train_preprocessed.shape[1]\n",
    "\n",
    "print(\"PyTorch Neural Network 10-fold CV Results:\")\n",
    "for i, (train_idx, val_idx) in enumerate(kf.split(X_train_preprocessed)):\n",
    "    # Split data\n",
    "    X_fold_train, X_fold_val = X_train_preprocessed[train_idx], X_train_preprocessed[val_idx]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model = train_nn(X_fold_train, y_fold_train, input_dim, epochs=50, batch_size=32)\n",
    "    \n",
    "    # Evaluate model\n",
    "    from scipy import sparse\n",
    "    if sparse.issparse(X_fold_val):\n",
    "        X_fold_val_tensor = torch.FloatTensor(X_fold_val.toarray())\n",
    "    else:\n",
    "        X_fold_val_tensor = torch.FloatTensor(X_fold_val)\n",
    "        \n",
    "    y_fold_val_tensor = torch.FloatTensor(y_fold_val.values).reshape(-1, 1)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_fold_val_tensor)\n",
    "        mse = nn.MSELoss()(y_pred, y_fold_val_tensor).item()\n",
    "        fold_rmse = np.sqrt(mse)\n",
    "    \n",
    "    nn_rmse_scores.append(fold_rmse)\n",
    "    print(f\"Fold {i+1} RMSE: {fold_rmse:.4f}\")\n",
    "\n",
    "print(f\"\\nMean RMSE: {np.mean(nn_rmse_scores):.4f}\")\n",
    "print(f\"Std RMSE: {np.std(nn_rmse_scores):.4f}\")\n",
    "\n",
    "# Train on the full training set\n",
    "final_nn_model = train_nn(X_train_preprocessed, y_train, input_dim, epochs=50, batch_size=32)\n",
    "\n",
    "# Evaluate on test set\n",
    "nn_test_rmse, nn_test_r2 = evaluate_nn(final_nn_model, X_test_preprocessed, y_test)\n",
    "\n",
    "print(f\"\\nTest RMSE: {nn_test_rmse:.4f}\")\n",
    "print(f\"Test R²: {nn_test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923ec43",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison table of model performances\n",
    "models = ['Ridge Regression', 'Lasso Regression', 'Random Forest', 'PyTorch Neural Network']\n",
    "cv_rmse = [ridge_rmse_scores.mean(), lasso_rmse_scores.mean(), rf_rmse_scores.mean(), np.mean(nn_rmse_scores)]\n",
    "test_rmse = [ridge_test_rmse, lasso_test_rmse, rf_test_rmse, nn_test_rmse]\n",
    "test_r2 = [ridge_test_r2, lasso_test_r2, rf_test_r2, nn_test_r2]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'CV RMSE': cv_rmse,\n",
    "    'Test RMSE': test_rmse,\n",
    "    'Test R²': test_r2\n",
    "})\n",
    "\n",
    "# Sort by test RMSE (lower is better)\n",
    "comparison_df = comparison_df.sort_values('Test RMSE')\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='Model', y='Test RMSE', data=comparison_df)\n",
    "plt.title('Model Comparison - Test RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# R² comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Model', y='Test R²', data=comparison_df)\n",
    "plt.title('Model Comparison - Test R²')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e635d68",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we built and evaluated four different regression models for the Ames Housing dataset:\n",
    "\n",
    "1. Ridge Regression\n",
    "2. Lasso Regression\n",
    "3. Random Forest Regression\n",
    "4. PyTorch Neural Network\n",
    "\n",
    "We performed proper data preprocessing, including missing value imputation, and evaluated each model using 10-fold cross-validation. The comparison table and visualization help identify the best performing model based on RMSE and R² metrics.\n",
    "\n",
    "The best performing model can be used for predicting house prices on new data."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
