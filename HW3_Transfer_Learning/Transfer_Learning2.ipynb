{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3452391-0953-4953-9c98-86bf03a2cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Starting MNIST to Letters Transfer Learning (Updated)\n",
      "üìÅ Expected folder structure:\n",
      "   Images/\n",
      "   ‚îú‚îÄ‚îÄ Training/ (A, B, C, D, E, NotA, NotB, NotC, NotD, NotE)\n",
      "   ‚îî‚îÄ‚îÄ Testing/  (A, B, C, D, E, NotA, NotB, NotC, NotD, NotE)\n",
      "üöÄ Initialized Transfer Learning Pipeline\n",
      "üìÅ Data directory: Images\n",
      "üî§ Letters to classify: ['A', 'B', 'C', 'D', 'E']\n",
      "üìè Image size: (28, 28)\n",
      "üöÄ MNIST TO LETTERS TRANSFER LEARNING PIPELINE (UPDATED)\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "STEP 1: TRAINING CNN ON FULL MNIST DATASET\n",
      "======================================================================\n",
      "üìä MNIST Training data shape: (60000, 28, 28, 1)\n",
      "üìä MNIST Training labels shape: (60000, 10)\n",
      "üìä MNIST Test data shape: (10000, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 12:33:51.072561: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-23 12:33:51.836360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30977 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:15:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèóÔ∏è  MNIST Model Architecture:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " mnist_output (Dense)        (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 159,882\n",
      "Trainable params: 159,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "üéØ Training MNIST model...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 12:33:54.239487: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 4ms/step - loss: 0.4027 - accuracy: 0.8711 - val_loss: 0.0787 - val_accuracy: 0.9765\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1095 - accuracy: 0.9683 - val_loss: 0.0602 - val_accuracy: 0.9821\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0779 - accuracy: 0.9773 - val_loss: 0.0540 - val_accuracy: 0.9853\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0659 - accuracy: 0.9811 - val_loss: 0.0512 - val_accuracy: 0.9861\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0520 - accuracy: 0.9847 - val_loss: 0.0503 - val_accuracy: 0.9856\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0420 - accuracy: 0.9876 - val_loss: 0.0481 - val_accuracy: 0.9872\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0400 - accuracy: 0.9883 - val_loss: 0.0505 - val_accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.0442 - val_accuracy: 0.9879\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.0445 - val_accuracy: 0.9886\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0439 - val_accuracy: 0.9891\n",
      "\n",
      "‚úÖ MNIST Training Results:\n",
      "   Training Time: 17.39 seconds\n",
      "   Final Training Accuracy: 0.9915\n",
      "   Final Validation Accuracy: 0.9891\n",
      "   Test Accuracy: 0.9891\n",
      "   Total Parameters: 159,882\n",
      "\n",
      "======================================================================\n",
      "STEP 2: LOADING LETTER DATASET\n",
      "======================================================================\n",
      "\n",
      "üìÇ Loading Training data from Images/Training\n",
      "   ‚úÖ Loaded 64 A images\n",
      "   ‚úÖ Loaded 64 B images\n",
      "   ‚úÖ Loaded 64 C images\n",
      "   ‚úÖ Loaded 64 D images\n",
      "   ‚úÖ Loaded 64 E images\n",
      "\n",
      "üìÇ Loading Testing data from Images/Testing\n",
      "   ‚úÖ Loaded 12 A images\n",
      "   ‚úÖ Loaded 12 B images\n",
      "   ‚úÖ Loaded 12 C images\n",
      "   ‚úÖ Loaded 12 D images\n",
      "   ‚úÖ Loaded 12 E images\n",
      "\n",
      "üìä Dataset Summary:\n",
      "   Training images: (320, 28, 28, 1)\n",
      "   Training labels: (320,)\n",
      "   Testing images: (60, 28, 28, 1)\n",
      "   Testing labels: (60,)\n",
      "\n",
      "üìà Class Distribution:\n",
      "   A: 64 training, 12 testing\n",
      "   B: 64 training, 12 testing\n",
      "   C: 64 training, 12 testing\n",
      "   D: 64 training, 12 testing\n",
      "   E: 64 training, 12 testing\n",
      "\n",
      "======================================================================\n",
      "STEP 3: CREATING BASE MODEL FOR TRANSFER LEARNING\n",
      "======================================================================\n",
      "üèóÔ∏è  Base model created from MNIST features:\n",
      "   Input shape: (None, 28, 28, 1)\n",
      "   Output shape: (None, 128)\n",
      "   Trainable parameters: 158,592\n",
      "\n",
      "======================================================================\n",
      "STEP 4: CREATING TRANSFER LEARNING MODEL\n",
      "======================================================================\n",
      "üèóÔ∏è  Transfer learning model created:\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 128)               158592    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " letter_output (Dense)       (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,749\n",
      "Trainable params: 17,157\n",
      "Non-trainable params: 158,592\n",
      "_________________________________________________________________\n",
      "\n",
      "üìä Parameter Analysis:\n",
      "   Total parameters: 175,749\n",
      "   Trainable parameters: 17,157 (9.8%)\n",
      "   Frozen parameters: 158,592 (90.2%)\n",
      "\n",
      "======================================================================\n",
      "STEP 5: TRAINING TRANSFER LEARNING MODEL\n",
      "======================================================================\n",
      "üìä Training with 320 samples\n",
      "üìä Testing with 60 samples\n",
      "\n",
      "ü•∂ Phase 1: Training with frozen base model...\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 1.5573 - accuracy: 0.2281 - val_loss: 1.5717 - val_accuracy: 0.2667\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.4652 - accuracy: 0.3344 - val_loss: 1.5462 - val_accuracy: 0.2667\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.4155 - accuracy: 0.4187 - val_loss: 1.5181 - val_accuracy: 0.4000\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.3542 - accuracy: 0.4531 - val_loss: 1.5129 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2877 - accuracy: 0.4437 - val_loss: 1.4674 - val_accuracy: 0.4000\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.2397 - accuracy: 0.5344 - val_loss: 1.4664 - val_accuracy: 0.4000\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2109 - accuracy: 0.4969 - val_loss: 1.4230 - val_accuracy: 0.4000\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1768 - accuracy: 0.5500 - val_loss: 1.4106 - val_accuracy: 0.4000\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1169 - accuracy: 0.5781 - val_loss: 1.4209 - val_accuracy: 0.4000\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1004 - accuracy: 0.5531 - val_loss: 1.4134 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1039 - accuracy: 0.5406 - val_loss: 1.3665 - val_accuracy: 0.4667\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0765 - accuracy: 0.5719 - val_loss: 1.3883 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0799 - accuracy: 0.5750 - val_loss: 1.3921 - val_accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0213 - accuracy: 0.5875 - val_loss: 1.3279 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0066 - accuracy: 0.6250 - val_loss: 1.3132 - val_accuracy: 0.4000\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.9941 - accuracy: 0.5781 - val_loss: 1.3238 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.9650 - accuracy: 0.6500 - val_loss: 1.3485 - val_accuracy: 0.4667\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.9643 - accuracy: 0.6500 - val_loss: 1.3115 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.9647 - accuracy: 0.5969 - val_loss: 1.2772 - val_accuracy: 0.4000\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.9538 - accuracy: 0.6219 - val_loss: 1.2685 - val_accuracy: 0.4000\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.9396 - accuracy: 0.6250 - val_loss: 1.2784 - val_accuracy: 0.4000\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.9466 - accuracy: 0.6125 - val_loss: 1.2643 - val_accuracy: 0.4000\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.9419 - accuracy: 0.6281 - val_loss: 1.2668 - val_accuracy: 0.4667\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.9295 - accuracy: 0.6281 - val_loss: 1.3132 - val_accuracy: 0.4000\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.9379 - accuracy: 0.5813 - val_loss: 1.2252 - val_accuracy: 0.4000\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8639 - accuracy: 0.6750 - val_loss: 1.2349 - val_accuracy: 0.4667\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8706 - accuracy: 0.6313 - val_loss: 1.2721 - val_accuracy: 0.4667\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8529 - accuracy: 0.6562 - val_loss: 1.2666 - val_accuracy: 0.4000\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8490 - accuracy: 0.6687 - val_loss: 1.2494 - val_accuracy: 0.4667\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8999 - accuracy: 0.6469 - val_loss: 1.2606 - val_accuracy: 0.4000\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8735 - accuracy: 0.6375 - val_loss: 1.2576 - val_accuracy: 0.4667\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8698 - accuracy: 0.6313 - val_loss: 1.2000 - val_accuracy: 0.4667\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8813 - accuracy: 0.6375 - val_loss: 1.2675 - val_accuracy: 0.4000\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8769 - accuracy: 0.6062 - val_loss: 1.1650 - val_accuracy: 0.4667\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8439 - accuracy: 0.6719 - val_loss: 1.2401 - val_accuracy: 0.4000\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8675 - accuracy: 0.6281 - val_loss: 1.1966 - val_accuracy: 0.4667\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8136 - accuracy: 0.6625 - val_loss: 1.2412 - val_accuracy: 0.5333\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8277 - accuracy: 0.6562 - val_loss: 1.1960 - val_accuracy: 0.5333\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8319 - accuracy: 0.6250 - val_loss: 1.2177 - val_accuracy: 0.4667\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8385 - accuracy: 0.6687 - val_loss: 1.2045 - val_accuracy: 0.5333\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8057 - accuracy: 0.6812 - val_loss: 1.1660 - val_accuracy: 0.4000\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8391 - accuracy: 0.6594 - val_loss: 1.1987 - val_accuracy: 0.4000\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7760 - accuracy: 0.6938 - val_loss: 1.2553 - val_accuracy: 0.4000\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8162 - accuracy: 0.6812 - val_loss: 1.2028 - val_accuracy: 0.4000\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8141 - accuracy: 0.6625 - val_loss: 1.2150 - val_accuracy: 0.4000\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7770 - accuracy: 0.6875 - val_loss: 1.1853 - val_accuracy: 0.5333\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7746 - accuracy: 0.6875 - val_loss: 1.2110 - val_accuracy: 0.4667\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7825 - accuracy: 0.7094 - val_loss: 1.1961 - val_accuracy: 0.5333\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7604 - accuracy: 0.6938 - val_loss: 1.1927 - val_accuracy: 0.4667\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.6750 - val_loss: 1.1065 - val_accuracy: 0.5333\n",
      "\n",
      "‚úÖ Phase 1 Results:\n",
      "   Training time: 3.12 seconds\n",
      "   Final training accuracy: 0.6750\n",
      "   Final validation accuracy: 0.5333\n",
      "\n",
      "üî• Phase 2: Fine-tuning with unfrozen base model...\n",
      "   Unfrozen - Trainable parameters: 175,749 (100.0%)\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 1s 10ms/step - loss: 0.6747 - accuracy: 0.7469 - val_loss: 1.0989 - val_accuracy: 0.5333\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.8375 - val_loss: 0.9878 - val_accuracy: 0.6000\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8656 - val_loss: 0.8678 - val_accuracy: 0.7333\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2917 - accuracy: 0.9469 - val_loss: 0.9129 - val_accuracy: 0.8000\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2210 - accuracy: 0.9625 - val_loss: 0.8803 - val_accuracy: 0.8000\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.9625 - val_loss: 0.8890 - val_accuracy: 0.8000\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9875 - val_loss: 0.9282 - val_accuracy: 0.7333\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1320 - accuracy: 0.9906 - val_loss: 0.8492 - val_accuracy: 0.8000\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9906 - val_loss: 0.8788 - val_accuracy: 0.8000\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0981 - accuracy: 0.9969 - val_loss: 0.8703 - val_accuracy: 0.8000\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9875 - val_loss: 0.9171 - val_accuracy: 0.8000\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9937 - val_loss: 0.9756 - val_accuracy: 0.8000\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9969 - val_loss: 0.9283 - val_accuracy: 0.8000\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9969 - val_loss: 0.9987 - val_accuracy: 0.8000\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9906 - val_loss: 0.9917 - val_accuracy: 0.8000\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9969 - val_loss: 0.9675 - val_accuracy: 0.8000\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 1.0201 - val_accuracy: 0.8000\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.1295 - val_accuracy: 0.8000\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 1.0945 - val_accuracy: 0.8000\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.1212 - val_accuracy: 0.8000\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.0873 - val_accuracy: 0.8000\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.1001 - val_accuracy: 0.8000\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 1.1797 - val_accuracy: 0.8000\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.1563 - val_accuracy: 0.8000\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.1790 - val_accuracy: 0.8000\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.1565 - val_accuracy: 0.8000\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.2945 - val_accuracy: 0.8000\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.3249 - val_accuracy: 0.8000\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.2233 - val_accuracy: 0.8000\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 1.2307 - val_accuracy: 0.8000\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.3412 - val_accuracy: 0.7333\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.3105 - val_accuracy: 0.8000\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.4707 - val_accuracy: 0.8000\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.4782 - val_accuracy: 0.8000\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.4395 - val_accuracy: 0.7333\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.5017 - val_accuracy: 0.8000\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.3259 - val_accuracy: 0.7333\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3014 - val_accuracy: 0.8000\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9969 - val_loss: 1.8856 - val_accuracy: 0.6667\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4987 - val_accuracy: 0.7333\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4564 - val_accuracy: 0.8000\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3763 - val_accuracy: 0.8000\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4618 - val_accuracy: 0.8000\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5365 - val_accuracy: 0.8000\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5702 - val_accuracy: 0.8000\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4838 - val_accuracy: 0.8000\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4906 - val_accuracy: 0.8000\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5713 - val_accuracy: 0.8000\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6014 - val_accuracy: 0.8000\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6013 - val_accuracy: 0.8000\n",
      "\n",
      "‚úÖ Phase 2 Results:\n",
      "   Fine-tuning time: 3.86 seconds\n",
      "   Final training accuracy: 1.0000\n",
      "   Final validation accuracy: 0.8000\n",
      "\n",
      "üéØ Final Transfer Learning Results:\n",
      "   Total training time: 6.99 seconds\n",
      "   Final test accuracy: 0.8000\n",
      "   Final test loss: 1.6013\n",
      "\n",
      "======================================================================\n",
      "STEP 6: COMPREHENSIVE MODEL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "üìä Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Letter_A       1.00      0.67      0.80        12\n",
      "    Letter_B       0.67      0.67      0.67        12\n",
      "    Letter_C       0.60      1.00      0.75        12\n",
      "    Letter_D       1.00      0.67      0.80        12\n",
      "    Letter_E       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.80        60\n",
      "   macro avg       0.85      0.80      0.80        60\n",
      "weighted avg       0.85      0.80      0.80        60\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Per-Class Performance Analysis:\n",
      "Letter   Accuracy   Samples  Correct  Incorrect \n",
      "--------------------------------------------------\n",
      "A        0.6667     12       8        4         \n",
      "B        0.6667     12       8        4         \n",
      "C        1.0000     12       12       0         \n",
      "D        0.6667     12       8        4         \n",
      "E        1.0000     12       12       0         \n",
      "--------------------------------------------------\n",
      "Overall  0.8000     60       48       12        \n",
      "\n",
      "üéØ Prediction Confidence Analysis:\n",
      "   Average confidence: 0.9158\n",
      "   Confidence std: 0.1786\n",
      "   Min confidence: 0.4297\n",
      "   Max confidence: 0.9998\n",
      "\n",
      "üéâ TRANSFER LEARNING PIPELINE COMPLETED!\n",
      "‚è±Ô∏è  Total execution time: 27.98 seconds\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Model saved as 'mnist_to_letters_transfer_updated.h5'\n",
      "\n",
      "üîç Testing sample predictions...\n",
      "\n",
      "üì∏ Sample Predictions:\n",
      "------------------------------------------------------------\n",
      "üì∑ Images/Testing/A/A1.jpg\n",
      "   Predicted: A (confidence: 0.9771)\n",
      "   All probs: A:0.977, B:0.023, C:0.000, D:0.000, E:0.000\n",
      "\n",
      "üì∑ Images/Testing/B/B1.jpg\n",
      "   Predicted: B (confidence: 0.9765)\n",
      "   All probs: A:0.018, B:0.976, C:0.000, D:0.005, E:0.000\n",
      "\n",
      "üì∑ Images/Testing/C/C1.jpg\n",
      "   Predicted: C (confidence: 0.9998)\n",
      "   All probs: A:0.000, B:0.000, C:1.000, D:0.000, E:0.000\n",
      "\n",
      "üì∑ Images/Testing/D/D1.jpg\n",
      "   Predicted: C (confidence: 0.9998)\n",
      "   All probs: A:0.000, B:0.000, C:1.000, D:0.000, E:0.000\n",
      "\n",
      "üì∑ Images/Testing/E/E1.jpg\n",
      "   Predicted: E (confidence: 0.9255)\n",
      "   All probs: A:0.035, B:0.020, C:0.001, D:0.019, E:0.925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Updated MNIST to Letters Transfer Learning Implementation\n",
    "\n",
    "This implementation works with the new folder structure:\n",
    "Images/\n",
    "‚îú‚îÄ‚îÄ Training/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ A/, B/, C/, D/, E/        (letter training images)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ NotA/, NotB/, NotC/, NotD/, NotE/  (non-letter training images)\n",
    "‚îî‚îÄ‚îÄ Testing/\n",
    "    ‚îú‚îÄ‚îÄ A/, B/, C/, D/, E/        (letter testing images)\n",
    "    ‚îî‚îÄ‚îÄ NotA/, NotB/, NotC/, NotD/, NotE/  (non-letter testing images)\n",
    "\n",
    "The script:\n",
    "1. Trains a CNN on full MNIST dataset (digits 0-9)\n",
    "2. Transfers the model to classify letters A, B, C, D, E\n",
    "3. Uses separate training and testing datasets\n",
    "4. Provides comprehensive performance evaluation\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class MNISTToLettersTransferUpdated:\n",
    "    def __init__(self, data_dir=\"Images\", img_size=(28, 28)):\n",
    "        \"\"\"\n",
    "        Initialize the transfer learning pipeline with updated folder structure.\n",
    "        \n",
    "        Args:\n",
    "            data_dir (str): Directory containing Training and Testing folders\n",
    "            img_size (tuple): Target image size (28x28 to match MNIST)\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.img_size = img_size\n",
    "        self.letters = ['A', 'B', 'C', 'D', 'E']\n",
    "        self.num_classes = len(self.letters)\n",
    "        \n",
    "        # Models\n",
    "        self.mnist_model = None\n",
    "        self.base_model = None\n",
    "        self.transfer_model = None\n",
    "        \n",
    "        # Data storage\n",
    "        self.train_data = None\n",
    "        self.train_labels = None\n",
    "        self.test_data = None\n",
    "        self.test_labels = None\n",
    "        \n",
    "        print(f\"üöÄ Initialized Transfer Learning Pipeline\")\n",
    "        print(f\"üìÅ Data directory: {self.data_dir}\")\n",
    "        print(f\"üî§ Letters to classify: {self.letters}\")\n",
    "        print(f\"üìè Image size: {self.img_size}\")\n",
    "\n",
    "    def create_mnist_model(self):\n",
    "        \"\"\"\n",
    "        Create and train CNN model on MNIST dataset.\n",
    "        \n",
    "        Returns:\n",
    "            tf.keras.Model: Trained MNIST model\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 1: TRAINING CNN ON FULL MNIST DATASET\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Load MNIST data\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "        \n",
    "        # Normalize pixel values\n",
    "        x_train = x_train.astype('float32') / 255.0\n",
    "        x_test = x_test.astype('float32') / 255.0\n",
    "        \n",
    "        # Reshape to add channel dimension\n",
    "        x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "        x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "        \n",
    "        # Convert labels to categorical\n",
    "        y_train_cat = tf.keras.utils.to_categorical(y_train, 10)\n",
    "        y_test_cat = tf.keras.utils.to_categorical(y_test, 10)\n",
    "        \n",
    "        print(f\"üìä MNIST Training data shape: {x_train.shape}\")\n",
    "        print(f\"üìä MNIST Training labels shape: {y_train_cat.shape}\")\n",
    "        print(f\"üìä MNIST Test data shape: {x_test.shape}\")\n",
    "        \n",
    "        # Create CNN model for MNIST\n",
    "        model = tf.keras.Sequential([\n",
    "            # Convolutional layers\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            \n",
    "            # Dense layers\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(10, activation='softmax', name='mnist_output')\n",
    "        ])\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        print(\"\\nüèóÔ∏è  MNIST Model Architecture:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train model\n",
    "        print(\"\\nüéØ Training MNIST model...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        history = model.fit(\n",
    "            x_train, y_train_cat,\n",
    "            batch_size=128,\n",
    "            epochs=10,\n",
    "            validation_data=(x_test, y_test_cat),\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Evaluate model\n",
    "        test_loss, test_accuracy = model.evaluate(x_test, y_test_cat, verbose=0)\n",
    "        \n",
    "        print(f\"\\n‚úÖ MNIST Training Results:\")\n",
    "        print(f\"   Training Time: {training_time:.2f} seconds\")\n",
    "        print(f\"   Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "        print(f\"   Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "        print(f\"   Test Accuracy: {test_accuracy:.4f}\")\n",
    "        print(f\"   Total Parameters: {model.count_params():,}\")\n",
    "        \n",
    "        self.mnist_model = model\n",
    "        return model\n",
    "\n",
    "    def load_letter_dataset(self):\n",
    "        \"\"\"\n",
    "        Load letter dataset from the new Training and Testing folder structure.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (train_data, train_labels, test_data, test_labels)\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 2: LOADING LETTER DATASET\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        def load_images_from_folders(base_path, folder_type):\n",
    "            \"\"\"Load images from Training or Testing folders.\"\"\"\n",
    "            images = []\n",
    "            labels = []\n",
    "            \n",
    "            print(f\"\\nüìÇ Loading {folder_type} data from {base_path}\")\n",
    "            \n",
    "            # Load positive examples for each letter\n",
    "            for i, letter in enumerate(self.letters):\n",
    "                letter_dir = os.path.join(base_path, letter)\n",
    "                \n",
    "                if os.path.exists(letter_dir):\n",
    "                    letter_images = []\n",
    "                    for img_file in os.listdir(letter_dir):\n",
    "                        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                            img_path = os.path.join(letter_dir, img_file)\n",
    "                            \n",
    "                            # Load and preprocess image\n",
    "                            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                            if img is not None:\n",
    "                                # Resize to 28x28 to match MNIST\n",
    "                                img = cv2.resize(img, self.img_size)\n",
    "                                # Normalize\n",
    "                                img = img.astype('float32') / 255.0\n",
    "                                \n",
    "                                letter_images.append(img)\n",
    "                                labels.append(i)  # 0=A, 1=B, 2=C, 3=D, 4=E\n",
    "                    \n",
    "                    images.extend(letter_images)\n",
    "                    print(f\"   ‚úÖ Loaded {len(letter_images)} {letter} images\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå Directory not found: {letter_dir}\")\n",
    "            \n",
    "            return np.array(images), np.array(labels)\n",
    "        \n",
    "        # Load training data\n",
    "        training_path = os.path.join(self.data_dir, \"Training\")\n",
    "        train_images, train_labels = load_images_from_folders(training_path, \"Training\")\n",
    "        \n",
    "        # Load testing data\n",
    "        testing_path = os.path.join(self.data_dir, \"Testing\")\n",
    "        test_images, test_labels = load_images_from_folders(testing_path, \"Testing\")\n",
    "        \n",
    "        # Reshape images to add channel dimension\n",
    "        train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "        test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "        \n",
    "        # Shuffle training data\n",
    "        train_images, train_labels = shuffle(train_images, train_labels, random_state=42)\n",
    "        \n",
    "        print(f\"\\nüìä Dataset Summary:\")\n",
    "        print(f\"   Training images: {train_images.shape}\")\n",
    "        print(f\"   Training labels: {train_labels.shape}\")\n",
    "        print(f\"   Testing images: {test_images.shape}\")\n",
    "        print(f\"   Testing labels: {test_labels.shape}\")\n",
    "        \n",
    "        # Print class distribution\n",
    "        print(f\"\\nüìà Class Distribution:\")\n",
    "        for i, letter in enumerate(self.letters):\n",
    "            train_count = np.sum(train_labels == i)\n",
    "            test_count = np.sum(test_labels == i)\n",
    "            print(f\"   {letter}: {train_count} training, {test_count} testing\")\n",
    "        \n",
    "        self.train_data = train_images\n",
    "        self.train_labels = train_labels\n",
    "        self.test_data = test_images\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "        return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "    def create_base_model(self):\n",
    "        \"\"\"\n",
    "        Create base model from trained MNIST model (without final layer).\n",
    "        \n",
    "        Returns:\n",
    "            tf.keras.Model: Base model for transfer learning\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 3: CREATING BASE MODEL FOR TRANSFER LEARNING\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if self.mnist_model is None:\n",
    "            raise ValueError(\"MNIST model must be trained first\")\n",
    "        \n",
    "        # Create base model by removing the final classification layer\n",
    "        base_model = tf.keras.Model(\n",
    "            inputs=self.mnist_model.input,\n",
    "            outputs=self.mnist_model.layers[-3].output  # Output before final Dense layer\n",
    "        )\n",
    "        \n",
    "        # Freeze base model layers initially\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        print(f\"üèóÔ∏è  Base model created from MNIST features:\")\n",
    "        print(f\"   Input shape: {base_model.input_shape}\")\n",
    "        print(f\"   Output shape: {base_model.output_shape}\")\n",
    "        print(f\"   Trainable parameters: {base_model.count_params():,}\")\n",
    "        \n",
    "        self.base_model = base_model\n",
    "        return base_model\n",
    "\n",
    "    def create_transfer_model(self, base_model):\n",
    "        \"\"\"\n",
    "        Create transfer learning model for letter classification.\n",
    "        \n",
    "        Args:\n",
    "            base_model: Pre-trained base model\n",
    "            \n",
    "        Returns:\n",
    "            tf.keras.Model: Transfer learning model\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 4: CREATING TRANSFER LEARNING MODEL\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Create new model with letter classification head\n",
    "        model = tf.keras.Sequential([\n",
    "            base_model,\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(self.num_classes, activation='softmax', name='letter_output')\n",
    "        ])\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        print(\"üèóÔ∏è  Transfer learning model created:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Print parameter breakdown\n",
    "        total_params = model.count_params()\n",
    "        trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "        frozen_params = total_params - trainable_params\n",
    "        \n",
    "        print(f\"\\nüìä Parameter Analysis:\")\n",
    "        print(f\"   Total parameters: {total_params:,}\")\n",
    "        print(f\"   Trainable parameters: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
    "        print(f\"   Frozen parameters: {frozen_params:,} ({frozen_params/total_params*100:.1f}%)\")\n",
    "        \n",
    "        self.transfer_model = model\n",
    "        return model\n",
    "\n",
    "    def train_transfer_model(self, fine_tune=True):\n",
    "        \"\"\"\n",
    "        Train the transfer learning model using two-phase approach.\n",
    "        \n",
    "        Args:\n",
    "            fine_tune (bool): Whether to fine-tune base model layers\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 5: TRAINING TRANSFER LEARNING MODEL\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if self.train_data is None or self.test_data is None:\n",
    "            raise ValueError(\"Letter dataset must be loaded first\")\n",
    "        \n",
    "        print(f\"üìä Training with {len(self.train_data)} samples\")\n",
    "        print(f\"üìä Testing with {len(self.test_data)} samples\")\n",
    "        \n",
    "        # Phase 1: Train with frozen base model\n",
    "        print(f\"\\nü•∂ Phase 1: Training with frozen base model...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        history1 = self.transfer_model.fit(\n",
    "            self.train_data, self.train_labels,\n",
    "            batch_size=16,\n",
    "            epochs=50,\n",
    "            validation_data=(self.test_data, self.test_labels),\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        phase1_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\n‚úÖ Phase 1 Results:\")\n",
    "        print(f\"   Training time: {phase1_time:.2f} seconds\")\n",
    "        print(f\"   Final training accuracy: {history1.history['accuracy'][-1]:.4f}\")\n",
    "        print(f\"   Final validation accuracy: {history1.history['val_accuracy'][-1]:.4f}\")\n",
    "        \n",
    "        # Phase 2: Fine-tune with unfrozen base model\n",
    "        if fine_tune:\n",
    "            print(f\"\\nüî• Phase 2: Fine-tuning with unfrozen base model...\")\n",
    "            \n",
    "            # Unfreeze base model\n",
    "            self.base_model.trainable = True\n",
    "            \n",
    "            # Use lower learning rate for fine-tuning\n",
    "            self.transfer_model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            # Print updated parameter counts\n",
    "            trainable_params = sum([tf.keras.backend.count_params(w) for w in self.transfer_model.trainable_weights])\n",
    "            total_params = self.transfer_model.count_params()\n",
    "            print(f\"   Unfrozen - Trainable parameters: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            history2 = self.transfer_model.fit(\n",
    "                self.train_data, self.train_labels,\n",
    "                batch_size=16,\n",
    "                epochs=50,\n",
    "                validation_data=(self.test_data, self.test_labels),\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            phase2_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"\\n‚úÖ Phase 2 Results:\")\n",
    "            print(f\"   Fine-tuning time: {phase2_time:.2f} seconds\")\n",
    "            print(f\"   Final training accuracy: {history2.history['accuracy'][-1]:.4f}\")\n",
    "            print(f\"   Final validation accuracy: {history2.history['val_accuracy'][-1]:.4f}\")\n",
    "            \n",
    "            total_training_time = phase1_time + phase2_time\n",
    "        else:\n",
    "            total_training_time = phase1_time\n",
    "        \n",
    "        # Final evaluation on test set\n",
    "        test_loss, test_accuracy = self.transfer_model.evaluate(self.test_data, self.test_labels, verbose=0)\n",
    "        \n",
    "        print(f\"\\nüéØ Final Transfer Learning Results:\")\n",
    "        print(f\"   Total training time: {total_training_time:.2f} seconds\")\n",
    "        print(f\"   Final test accuracy: {test_accuracy:.4f}\")\n",
    "        print(f\"   Final test loss: {test_loss:.4f}\")\n",
    "        \n",
    "        return self.transfer_model\n",
    "\n",
    "    def evaluate_model_comprehensive(self):\n",
    "        \"\"\"\n",
    "        Perform comprehensive model evaluation with detailed metrics.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 6: COMPREHENSIVE MODEL EVALUATION\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = self.transfer_model.predict(self.test_data, verbose=0)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        # Classification report\n",
    "        letter_names = [f\"Letter_{letter}\" for letter in self.letters]\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(self.test_labels, predicted_classes, target_names=letter_names))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(self.test_labels, predicted_classes)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=self.letters, yticklabels=self.letters)\n",
    "        plt.title('Confusion Matrix - Transfer Learning Results\\n(Rows: True Labels, Columns: Predicted Labels)')\n",
    "        plt.xlabel('Predicted Letter')\n",
    "        plt.ylabel('True Letter')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('transfer_learning_confusion_matrix_updated.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Per-class accuracy analysis\n",
    "        print(f\"\\nüìà Per-Class Performance Analysis:\")\n",
    "        print(f\"{'Letter':<8} {'Accuracy':<10} {'Samples':<8} {'Correct':<8} {'Incorrect':<10}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        overall_correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for i, letter in enumerate(self.letters):\n",
    "            class_mask = self.test_labels == i\n",
    "            class_samples = np.sum(class_mask)\n",
    "            \n",
    "            if class_samples > 0:\n",
    "                class_correct = np.sum(predicted_classes[class_mask] == i)\n",
    "                class_accuracy = class_correct / class_samples\n",
    "                class_incorrect = class_samples - class_correct\n",
    "                \n",
    "                print(f\"{letter:<8} {class_accuracy:<10.4f} {class_samples:<8} {class_correct:<8} {class_incorrect:<10}\")\n",
    "                \n",
    "                overall_correct += class_correct\n",
    "                total_samples += class_samples\n",
    "        \n",
    "        overall_accuracy = overall_correct / total_samples if total_samples > 0 else 0\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'Overall':<8} {overall_accuracy:<10.4f} {total_samples:<8} {overall_correct:<8} {total_samples-overall_correct:<10}\")\n",
    "        \n",
    "        # Prediction confidence analysis\n",
    "        prediction_confidences = np.max(predictions, axis=1)\n",
    "        print(f\"\\nüéØ Prediction Confidence Analysis:\")\n",
    "        print(f\"   Average confidence: {np.mean(prediction_confidences):.4f}\")\n",
    "        print(f\"   Confidence std: {np.std(prediction_confidences):.4f}\")\n",
    "        print(f\"   Min confidence: {np.min(prediction_confidences):.4f}\")\n",
    "        print(f\"   Max confidence: {np.max(prediction_confidences):.4f}\")\n",
    "\n",
    "    def predict_letter(self, image_path):\n",
    "        \"\"\"\n",
    "        Predict letter for a single image.\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to image file\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (predicted_letter, confidence, all_probabilities)\n",
    "        \"\"\"\n",
    "        if self.transfer_model is None:\n",
    "            raise ValueError(\"Transfer model must be trained first\")\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        # Preprocess\n",
    "        img = cv2.resize(img, self.img_size)\n",
    "        img = img.astype('float32') / 255.0\n",
    "        img = img.reshape(1, 28, 28, 1)\n",
    "        \n",
    "        # Predict\n",
    "        predictions = self.transfer_model.predict(img, verbose=0)\n",
    "        predicted_class = np.argmax(predictions[0])\n",
    "        predicted_letter = self.letters[predicted_class]\n",
    "        confidence = predictions[0][predicted_class]\n",
    "        \n",
    "        return predicted_letter, confidence, predictions[0]\n",
    "\n",
    "    def run_complete_pipeline(self):\n",
    "        \"\"\"\n",
    "        Run the complete transfer learning pipeline.\n",
    "        \"\"\"\n",
    "        print(\"üöÄ MNIST TO LETTERS TRANSFER LEARNING PIPELINE (UPDATED)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        total_start_time = time.time()\n",
    "        \n",
    "        # Step 1: Train MNIST model\n",
    "        self.create_mnist_model()\n",
    "        \n",
    "        # Step 2: Load letter dataset\n",
    "        self.load_letter_dataset()\n",
    "        \n",
    "        # Step 3: Create base model\n",
    "        base_model = self.create_base_model()\n",
    "        \n",
    "        # Step 4: Create transfer model\n",
    "        self.create_transfer_model(base_model)\n",
    "        \n",
    "        # Step 5: Train transfer model\n",
    "        self.train_transfer_model(fine_tune=True)\n",
    "        \n",
    "        # Step 6: Comprehensive evaluation\n",
    "        self.evaluate_model_comprehensive()\n",
    "        \n",
    "        total_time = time.time() - total_start_time\n",
    "        \n",
    "        print(f\"\\nüéâ TRANSFER LEARNING PIPELINE COMPLETED!\")\n",
    "        print(f\"‚è±Ô∏è  Total execution time: {total_time:.2f} seconds\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return self.transfer_model\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the updated transfer learning experiment.\"\"\"\n",
    "    \n",
    "    print(\"üéØ Starting MNIST to Letters Transfer Learning (Updated)\")\n",
    "    print(\"üìÅ Expected folder structure:\")\n",
    "    print(\"   Images/\")\n",
    "    print(\"   ‚îú‚îÄ‚îÄ Training/ (A, B, C, D, E, NotA, NotB, NotC, NotD, NotE)\")\n",
    "    print(\"   ‚îî‚îÄ‚îÄ Testing/  (A, B, C, D, E, NotA, NotB, NotC, NotD, NotE)\")\n",
    "    \n",
    "    # Verify folder structure\n",
    "    if not os.path.exists(\"Images/Training\") or not os.path.exists(\"Images/Testing\"):\n",
    "        print(\"‚ùå Error: Required folder structure not found!\")\n",
    "        print(\"   Please ensure Images/Training and Images/Testing directories exist.\")\n",
    "        return\n",
    "    \n",
    "    # Create transfer learning pipeline\n",
    "    transfer_pipeline = MNISTToLettersTransferUpdated(data_dir=\"Images\")\n",
    "    \n",
    "    # Run complete pipeline\n",
    "    model = transfer_pipeline.run_complete_pipeline()\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_path = 'mnist_to_letters_transfer_updated.h5'\n",
    "    model.save(model_path)\n",
    "    print(f\"\\n‚úÖ Model saved as '{model_path}'\")\n",
    "    \n",
    "    # Test predictions on sample images (if available)\n",
    "    print(f\"\\nüîç Testing sample predictions...\")\n",
    "    sample_images = [\n",
    "        \"Images/Testing/A/A1.jpg\",\n",
    "        \"Images/Testing/B/B1.jpg\", \n",
    "        \"Images/Testing/C/C1.jpg\",\n",
    "        \"Images/Testing/D/D1.jpg\",\n",
    "        \"Images/Testing/E/E1.jpg\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüì∏ Sample Predictions:\")\n",
    "    print(\"-\" * 60)\n",
    "    for img_path in sample_images:\n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                predicted_letter, confidence, all_probs = transfer_pipeline.predict_letter(img_path)\n",
    "                print(f\"üì∑ {img_path}\")\n",
    "                print(f\"   Predicted: {predicted_letter} (confidence: {confidence:.4f})\")\n",
    "                \n",
    "                # Show all probabilities\n",
    "                prob_str = \", \".join([f\"{letter}:{prob:.3f}\" for letter, prob in zip(transfer_pipeline.letters, all_probs)])\n",
    "                print(f\"   All probs: {prob_str}\")\n",
    "                print()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error predicting {img_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  File not found: {img_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e6669-d62e-4441-9a19-952ed5d8f941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac2792-b338-4de1-b008-3050dfd06173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorflowGPU29",
   "language": "python",
   "name": "tensorflow_2.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
